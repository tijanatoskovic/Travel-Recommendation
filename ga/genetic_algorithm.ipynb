{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual:\n",
    "    \"\"\"\n",
    "    Our Individual is a neural network\n",
    "    code - flattened weights and biases\n",
    "    fitness - performance of the NN on a dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, X, y):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.X = X  # input data\n",
    "        self.y = y  # target data\n",
    "\n",
    "        # Initialize weights and biases randomly\n",
    "        self.W1 = np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.random.randn(hidden_size)\n",
    "        self.W2 = np.random.randn(hidden_size, output_size)\n",
    "        self.b2 = np.random.randn(output_size)\n",
    "\n",
    "        # Flatten all weights into a code for GA\n",
    "        self.code = self.flatten_weights()\n",
    "        self.calc_fitness()\n",
    "\n",
    "    def flatten_weights(self):\n",
    "        \"\"\"Flatten all weights and biases into a 1D array\"\"\"\n",
    "        return np.concatenate([\n",
    "            self.W1.flatten(),\n",
    "            self.b1.flatten(),\n",
    "            self.W2.flatten(),\n",
    "            self.b2.flatten()\n",
    "        ])\n",
    "\n",
    "    def unflatten_weights(self):\n",
    "        idx = 0\n",
    "        W1_size = self.input_size * self.hidden_size\n",
    "        self.W1 = self.code[idx:idx+W1_size].reshape(self.input_size, self.hidden_size)\n",
    "        idx += W1_size\n",
    "\n",
    "        self.b1 = self.code[idx:idx+self.hidden_size]\n",
    "        idx += self.hidden_size\n",
    "\n",
    "        W2_size = self.hidden_size * self.output_size\n",
    "        self.W2 = self.code[idx:idx+W2_size].reshape(self.hidden_size, self.output_size)\n",
    "        idx += W2_size\n",
    "\n",
    "        self.b2 = self.code[idx:idx+self.output_size]\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Feedforward pass\"\"\"\n",
    "        h = np.tanh(np.dot(X, self.W1) + self.b1)\n",
    "        logits = np.dot(h, self.W2) + self.b2\n",
    "        # Softmax for probabilities\n",
    "        exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "        probs = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "        return probs\n",
    "\n",
    "    def calc_fitness(self):\n",
    "        self.unflatten_weights()\n",
    "        probs = self.forward(self.X)  # compute predicted probabilities\n",
    "        y_pred = np.argmax(probs, axis=1)  # predicted class for each sample\n",
    "        accuracy = np.mean(y_pred == self.y)  # fraction of correct predictions\n",
    "        self.fitness = accuracy  # higher is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selection(population: list, k: int, method: str = \"tournament\"):\n",
    "    \"\"\"\n",
    "    Selects an individual from the population based on fitness.\n",
    "\n",
    "    Parameters:\n",
    "        population - list of Individuals (with NN code & fitness)\n",
    "        k          - tournament size (for tournament selection)\n",
    "        method     - either \"tournament\" or \"roulette\"\n",
    "    \"\"\"\n",
    "    if method == \"tournament\":\n",
    "        # Tournament selection\n",
    "        k = min(len(population), k)\n",
    "        participants = random.sample(population, k)\n",
    "        return max(participants, key=lambda x: x.fitness)\n",
    "\n",
    "    # TODO: add roulette\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2, child1, child2):\n",
    "    # Pick a random point in the flattened code array\n",
    "    breakpoint = random.randrange(1, len(parent1.code))\n",
    "\n",
    "    # Mix the weights\n",
    "    child1.code[:breakpoint] = parent1.code[:breakpoint]\n",
    "    child1.code[breakpoint:] = parent2.code[breakpoint:]\n",
    "\n",
    "    child2.code[:breakpoint] = parent2.code[:breakpoint]\n",
    "    child2.code[breakpoint:] = parent1.code[breakpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(child: Individual, p: float, sigma: float = 0.1):\n",
    "    \"\"\"\n",
    "    With probability p, add Gaussian noise to each weight in the network.\n",
    "\n",
    "    p     - probability of mutating each weight\n",
    "    sigma - standard deviation of noise\n",
    "    \"\"\"\n",
    "    for i in range(len(child.code)):\n",
    "        if random.random() < p:\n",
    "            child.code[i] += np.random.normal(0, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def ga(X, y, input_size, hidden_size, output_size,\n",
    "          population_size=20, num_generations=50,\n",
    "          tournament_size=3, mutation_prob=0.1, elitism_size=2):\n",
    "\n",
    "    \"\"\"\n",
    "    Genetic Algorithm for evolving a neural network\n",
    "\n",
    "    X, y           : training data and labels\n",
    "    input_size      : number of input features\n",
    "    hidden_size     : number of neurons in hidden layer\n",
    "    output_size     : number of output classes\n",
    "    population_size : individuals per generation\n",
    "    num_generations : GA iterations\n",
    "    tournament_size : tournament selection size\n",
    "    mutation_prob   : probability of mutating each weight\n",
    "    elitism_size    : number of best individuals copied to next generation\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize population\n",
    "    population = [Individual(input_size, hidden_size, output_size, X, y) for _ in range(population_size)]\n",
    "    new_population = [Individual(input_size, hidden_size, output_size, X, y) for _ in range(population_size)]\n",
    "\n",
    "    # Adjust elitism to match parity with population size\n",
    "    if elitism_size % 2 != population_size % 2:\n",
    "        elitism_size += 1\n",
    "\n",
    "    best_fitnesses = []\n",
    "\n",
    "    for generation in range(num_generations):\n",
    "        # Sort population by fitness (accuracy)\n",
    "        population.sort(key=lambda x: x.fitness, reverse=True)\n",
    "        best_fitnesses.append(population[0].fitness)\n",
    "        print(f\"Generation {generation}: Best accuracy = {population[0].fitness:.4f}\")\n",
    "\n",
    "        # Elitism: carry best individuals directly to new population\n",
    "        new_population[:elitism_size] = deepcopy(population[:elitism_size])\n",
    "\n",
    "        # Fill the rest of the new population via crossover + mutation\n",
    "        for i in range(elitism_size, population_size, 2):\n",
    "            parent1 = selection(population, tournament_size)\n",
    "            # temporarily set fitness to -inf to avoid selecting same parent\n",
    "            tmp, parent1.fitness = parent1.fitness, float('-inf')\n",
    "            parent2 = selection(population, tournament_size)\n",
    "            parent1.fitness = tmp\n",
    "\n",
    "            # Create children via crossover\n",
    "            crossover(parent1, parent2, new_population[i], new_population[i+1])\n",
    "\n",
    "            # Mutate children\n",
    "            mutation(new_population[i], mutation_prob)\n",
    "            mutation(new_population[i+1], mutation_prob)\n",
    "\n",
    "            # Evaluate fitness (accuracy)\n",
    "            new_population[i].calc_fitness()\n",
    "            new_population[i+1].calc_fitness()\n",
    "\n",
    "        # Replace old population\n",
    "        population = deepcopy(new_population)\n",
    "\n",
    "    # Return best individual\n",
    "    best_individual = max(population, key=lambda x: x.fitness)\n",
    "    print(f'\\nBest accuracy: {best_individual.fitness:.4f}')\n",
    "    plt.plot(best_fitnesses)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Best Accuracy')\n",
    "    plt.title('GA Neural Network Evolution')\n",
    "    plt.show()\n",
    "\n",
    "    return best_individual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['label', 'user_id', 'destination', 'dest_key'])\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "\"\"\"\n",
    "As we can see above, there are multiple rows per user, so we have to make sure that all data from the same user stays\n",
    "together in either train, validation, or test set. GroupShuffleSplit is going to ensure exactly that.\n",
    "\"\"\"\n",
    "\n",
    "groups = df['user_id']\n",
    "\n",
    "# First, we split the data into train set and the rest\n",
    "split1 = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "train_idx, other_idx = next(split1.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_other = X.iloc[train_idx], X.iloc[other_idx]\n",
    "y_train, y_other = y.iloc[train_idx], y.iloc[other_idx]\n",
    "other_groups = groups.iloc[other_idx]\n",
    "\n",
    "# Then we split the rest of the data into validation and test sets\n",
    "split2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "val_idx, test_idx = next(split2.split(X_other, y_other, groups=other_groups))\n",
    "\n",
    "X_val, X_test = X_other.iloc[val_idx], X_other.iloc[test_idx]\n",
    "y_val, y_test = y_other.iloc[val_idx], y_other.iloc[test_idx]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['season', 'activity_level', 'safety_conscious', 'popularity', 'traveller_type']\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', 'passthrough', numeric_cols)                                    # leave numeric columns unchanged\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_final = preprocessor.fit_transform(X_train)\n",
    "X_val_final   = preprocessor.transform(X_val)\n",
    "X_test_final  = preprocessor.transform(X_test)\n",
    "\n",
    "X_train_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_size = X_train_final.shape[1]         # 71 features\n",
    "hidden_size = 32                            # hidden layer neurons\n",
    "output_size = len(np.unique(y))             # 2 classes\n",
    "population_size = 50\n",
    "num_generations = 50\n",
    "tournament_size = 3\n",
    "mutation_prob = 0.2\n",
    "elitism_size = 2\n",
    "\n",
    "best_nn = ga(\n",
    "    X=X_train_final,\n",
    "    y=y_train,\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    population_size=population_size,\n",
    "    num_generations=num_generations,\n",
    "    tournament_size=tournament_size,\n",
    "    mutation_prob=mutation_prob,\n",
    "    elitism_size=elitism_size\n",
    ")\n",
    "\n",
    "y_pred_test = np.argmax(best_nn.forward(X_test_final), axis=1)\n",
    "accuracy_test = np.mean(y_pred_test == y_test)\n",
    "print(f\"\\nTest set accuracy: {accuracy_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
