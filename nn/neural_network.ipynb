{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/travel_preferences.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Rating_0', 'Rating_1', 'Rating_2', 'Rating_3', 'Rating_4',\n",
    "       'Rating_5', 'Rating_6', 'Rating_7', 'Rating_8', 'Rating_9', 'Rec_0',\n",
    "       'Rec_1', 'Rec_2', 'Rec_3', 'Rec_4', 'Rec_5', 'Rec_6', 'Rec_7', 'Rec_8',\n",
    "       'Rec_9', 'where_to_go', 'where_to_go_exactly', 'Model', 'Retrieval',\n",
    "       'DynaMatch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('true_travel_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proveri missing values\n",
    "print(\"Missing values po kolonama:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]\n",
    "#Vidimo da smo izgubili redove, ali i dalje imamo puno instanci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def to_list(x):\n",
    "    if pd.isna(x) or x == '' or x == '[]':\n",
    "        return []\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    return ast.literal_eval(x)\n",
    "\n",
    "for col in ['yes_swipes', 'no_swipes', 'maybe_swipes',\n",
    "    'age_ranges', 'budget_ranges',\n",
    "    'interests', 'sceneries']:\n",
    "    df[col] = df[col].apply(to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traveller_type(age_ranges):\n",
    "    n = len(age_ranges)\n",
    "    if n <= 1:\n",
    "        return 'solo'\n",
    "    elif n == 2:\n",
    "        return 'couple'\n",
    "    else:\n",
    "        return 'friends'\n",
    "\n",
    "df['traveller_type'] = df['age_ranges'].apply(traveller_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb_interests = MultiLabelBinarizer()\n",
    "interest_df = pd.DataFrame(\n",
    "    mlb_interests.fit_transform(df['interests']),\n",
    "    columns=[f\"interest_{c}\" for c in mlb_interests.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df = pd.concat([df, interest_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='interests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_budget = MultiLabelBinarizer()\n",
    "budget_df = pd.DataFrame(\n",
    "    mlb_budget.fit_transform(df['budget_ranges']),\n",
    "    columns=[f\"budget_{c}\" for c in mlb_budget.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df = pd.concat([df, budget_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_scene = MultiLabelBinarizer()\n",
    "scene_df = pd.DataFrame(\n",
    "    mlb_scene.fit_transform(df['sceneries']),\n",
    "    columns=[f\"scene_{c}\" for c in mlb_scene.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df = pd.concat([df, scene_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_age = MultiLabelBinarizer()\n",
    "age_df = pd.DataFrame(\n",
    "    mlb_age.fit_transform(df['age_ranges']),\n",
    "    columns=[f\"age_{c}\" for c in mlb_age.classes_],\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df = pd.concat([df, age_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['sceneries', 'budget_ranges', 'age_ranges'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ucitavanje destinacija\n",
    "dest1 = pd.read_csv('../data/DestinationFeatures/city_onehot_features_part_01.csv')\n",
    "dest2 = pd.read_csv('../data/DestinationFeatures/city_onehot_features_part_02.csv')\n",
    "dest3 = pd.read_csv('../data/DestinationFeatures/city_onehot_features_part_03.csv')\n",
    "dest4 = pd.read_csv('../data/DestinationFeatures/city_onehot_features_part_04.csv')\n",
    "\n",
    "dest = pd.concat([dest1, dest2, dest3, dest4], ignore_index=True)\n",
    "\n",
    "dest['destination_full'] = dest['city'].astype(str).str.strip() + ', ' + dest['country'].astype(str).str.strip()\n",
    "\n",
    "import re, unicodedata\n",
    "#zelimo da se otarasimo specijalnih karaktera u nazivima gradova\n",
    "def norm_key(s: str) -> str:\n",
    "    s = str(s).strip().lower()\n",
    "    s = unicodedata.normalize('NFKD', s)\n",
    "    s = ''.join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = s.replace('&', 'and')\n",
    "    s = re.sub(r\"[â€™'`\\.]\", \"\", s)\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "dest['dest_key'] = dest['destination_full'].apply(norm_key)\n",
    "\n",
    "dest_feat = dest.drop(columns=['city','country','destination_full'])\n",
    "\n",
    "dest_keys = set(dest_feat['dest_key'])\n",
    "print('Destinations loaded:', len(dest_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dest1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# ne zelimo da imamo previse negativnih misljenja za destinacije, pa za svakog usera dozvolimo po 1 koja mu se svidja 2 negativne\n",
    "\n",
    "NEG_RATIO = 2\n",
    "MAX_NEG_PER_USER = 40\n",
    "\n",
    "rows = [] # instance koje cemo koristiti\n",
    "skipped = 0\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    user_id = row['id']\n",
    "\n",
    "    yes = [d for d in row['yes_swipes'] if norm_key(d) in dest_keys]\n",
    "    # model ne moze da uci ukoliko nemamo pozitivnih instanci za usera pa ih preskacemo\n",
    "    if len(yes) == 0:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "    no = [d for d in row['no_swipes'] if norm_key(d) in dest_keys]\n",
    "\n",
    "    k = min(len(no), MAX_NEG_PER_USER, NEG_RATIO * len(yes))\n",
    "    if k > 0 and len(no) > k:\n",
    "        no = random.sample(no, k)\n",
    "\n",
    "    for d in yes:\n",
    "        rows.append([user_id, d, 1])\n",
    "    for d in no:\n",
    "        rows.append([user_id, d, 0])\n",
    "\n",
    "interactions = pd.DataFrame(rows, columns=['user_id', 'destination', 'label'])\n",
    "interactions['dest_key'] = interactions['destination'].apply(norm_key)\n",
    "\n",
    "print('Skipped users:', skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umesto (user, [gradovi]), zelimo (user, grad)\n",
    "feature_cols = [\n",
    "    'season',\n",
    "    'activity_level',\n",
    "    'safety_conscious',\n",
    "    'popularity',\n",
    "    'traveller_type',\n",
    "\n",
    "    'interest_Adventure',\n",
    "    'interest_Beach',\n",
    "    'interest_Cuisine',\n",
    "    'interest_Culture',\n",
    "    'interest_History',\n",
    "    'interest_Nature',\n",
    "    'interest_Nightlife',\n",
    "    'interest_Shopping',\n",
    "\n",
    "    'budget_0-49',\n",
    "    'budget_50-99',\n",
    "    'budget_100-249',\n",
    "    'budget_300+',\n",
    "\n",
    "    'scene_Desert',\n",
    "    'scene_Jungle',\n",
    "    'scene_Lake',\n",
    "    'scene_Mountain',\n",
    "    'scene_Plains',\n",
    "    'scene_Rural',\n",
    "    'scene_Sea',\n",
    "    'scene_Urban',\n",
    "\n",
    "    'age_0-19',\n",
    "    'age_20-39',\n",
    "    'age_40-59',\n",
    "    'age_60+'\n",
    "]\n",
    "\n",
    "# User feature frame\n",
    "user_feat = df[['id'] + feature_cols].rename(columns={'id':'user_id'}).copy()\n",
    "\n",
    "# Destination feature columns (everything except dest_key)\n",
    "dest_cols = [c for c in dest_feat.columns if c != 'dest_key']\n",
    "\n",
    "# Final training table\n",
    "train_df = interactions.merge(user_feat, on='user_id', how='left').merge(dest_feat, on='dest_key', how='left')\n",
    "train_df = train_df.dropna()\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(columns=['label', 'user_id', 'destination', 'dest_key'])\n",
    "y = train_df['label'].astype(int)\n",
    "\n",
    "categorical_cols = ['season','activity_level','safety_conscious','popularity','traveller_type']\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "groups = train_df['user_id']\n",
    "\n",
    "split1 = GroupShuffleSplit(n_splits=1, test_size=0.30, random_state=42)\n",
    "train_idx, tmp_idx = next(split1.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_tmp = X.iloc[train_idx], X.iloc[tmp_idx]\n",
    "y_train, y_tmp = y.iloc[train_idx], y.iloc[tmp_idx]\n",
    "g_tmp = groups.iloc[tmp_idx]\n",
    "\n",
    "split2 = GroupShuffleSplit(n_splits=1, test_size=0.50, random_state=42)\n",
    "val_idx, test_idx = next(split2.split(X_tmp, y_tmp, groups=g_tmp))\n",
    "\n",
    "X_val, X_test = X_tmp.iloc[val_idx], X_tmp.iloc[test_idx]\n",
    "y_val, y_test = y_tmp.iloc[val_idx], y_tmp.iloc[test_idx]\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', 'passthrough', numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc   = preprocessor.transform(X_val)\n",
    "X_test_proc  = preprocessor.transform(X_test)\n",
    "\n",
    "print(X_train_proc.shape, X_val_proc.shape, X_test_proc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        \n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        \n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(X_train_proc.shape[1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        keras.metrics.AUC(name='auc'),\n",
    "        keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.array([0, 1]),\n",
    "    y=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_train.unique())\n",
    "print(type(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = y_train.to_numpy().astype('float32')\n",
    "y_val_np   = y_val.to_numpy().astype('float32')\n",
    "y_test_np  = y_test.to_numpy().astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_auc',\n",
    "        patience=3,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_np = y_train.to_numpy().astype('float32')\n",
    "y_val_np   = y_val.to_numpy().astype('float32')\n",
    "y_test_np  = y_test.to_numpy().astype('float32')\n",
    "\n",
    "X_train_proc = X_train_proc.astype(\"float32\")\n",
    "X_val_proc   = X_val_proc.astype(\"float32\")\n",
    "X_test_proc  = X_test_proc.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(f\"Class weights: {class_weight_dict}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train_np,\n",
    "    validation_data=(X_val_proc, y_val_np),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "print(\"\\n Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Binary Crossentropy Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['auc'], label='train_auc')\n",
    "plt.plot(history.history['val_auc'], label='val_auc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Training vs Validation AUC')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred_probs = model.predict(X_test_proc, batch_size=1024)\n",
    "\n",
    "y_pred = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_pred_probs))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
